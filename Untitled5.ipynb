{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/T967qNu6Uc2tHBVFDwCi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anuragsingh24082004/FUNCTIONS-PRACTICAL/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GOOGLE DRIVE LINK - https://colab.research.google.com/drive/1cY1VTElH0Z-SjLhJJz5cDSWnbs8dheG_\n",
        "\n",
        "GITHUB LINK -"
      ],
      "metadata": {
        "id": "hH7oNFGDkEZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# THEORETICAL QUESTIONS -"
      ],
      "metadata": {
        "id": "_b-66d4Fj_Bw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1 - WHAT IS TENSORFLOW 2.0, AND HOW IS IT DIFFERENT FROM TENSORFLOW 1\n",
        "X?**"
      ],
      "metadata": {
        "id": "ifDu1C5U3VXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER 1:\n",
        "TENSORFLOW 2.0 IS THE UPGRADED VERSION OF TENSORFLOW THAT FOCUSES ON SIMPLICITY AND EASE OF USE. IT INTEGRATES KERAS AS ITS HIGH-LEVEL API, SUPPORTS EAGER EXECUTION BY DEFAULT, AND REMOVES MANY OF THE COMPLEXITIES FOUND IN TENSORFLOW 1.X."
      ],
      "metadata": {
        "id": "I7U787HjfR6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2- HOW DO YOU INSTALL TENSORFLOW 2.0?**"
      ],
      "metadata": {
        "id": "5TWEPRQC3FwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO INSTALL TENSORFLOW 2.0 WE USE -\n",
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "F2WooevnfdCQ",
        "outputId": "b39fbc15-28f6-4bf5-fc36-1d017f7093e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxbSfCVkhcdZ",
        "outputId": "427892bc-ace7-4f04-a572-d1193d004c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3- WHAT IS THE PRIMARY FUNCTION OF THE TF.FUNCTION IN TENSORFLOW 2.0?**"
      ],
      "metadata": {
        "id": "UQFNs7Go3Ftx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER 3:\n",
        "THE TF.FUNCTION DECORATOR IS USED TO CONVERT A PYTHON FUNCTION INTO A TENSORFLOW COMPUTATION GRAPH. THIS OPTIMIZATION IMPROVES PERFORMANCE AND ALLOWS FOR BETTER DEPLOYMENT ACROSS PLATFORMS."
      ],
      "metadata": {
        "id": "Je5dkOqyfttY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4- WHAT IS THE PURPOSE OF THE MODEL CLASS IN TENSORFLOW 2.0?**"
      ],
      "metadata": {
        "id": "o76oWDsD3Frh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "THE MODEL CLASS IN TENSORFLOW 2.0 (FROM TF.KERAS.MODEL) SERVES AS A BASE CLASS TO BUILD CUSTOM DEEP LEARNING MODELS. IT ENABLES US TO DEFINE THE FORWARD PASS AND MANAGE TRAINING, EVALUATION, AND PREDICTION LOGIC."
      ],
      "metadata": {
        "id": "-Ga_es2_fxfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5- HOW DO YOU CREATE A NEURAL NETWORK USING TENSORFLOW 2.0?**"
      ],
      "metadata": {
        "id": "wGCrOqz03FpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we can create a neural network using the terminal API frim keras in tensorflow\n",
        "#example -\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n"
      ],
      "metadata": {
        "id": "G8WCx-cbf291"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6- WHAT IS THE IMPORTANCE OF TENSOR SPACE IN TENSORFLOW?**"
      ],
      "metadata": {
        "id": "owD7R16Y3Fme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER6-\n",
        "TENSOR SPACE REFERS TO THE MULTIDIMENSIONAL SPACE IN WHICH TENSORS EXIST. IN TENSORFLOW, TENSORS ARE THE CORE DATA STRUCTURE USED TO REPRESENT AND MANIPULATE ALL FORMS OF NUMERICAL DATA EFFICIENTLY."
      ],
      "metadata": {
        "id": "Nsq-axF-hnRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7- HOW CAN TENSORBOARD BE INTEGRATED WITH TENSORFLOW 2.0?**"
      ],
      "metadata": {
        "id": "35RF3m3S3Fjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER 7:\n",
        "TENSORBOARD CAN BE INTEGRATED BY USING THE TENSORBOARD CALLBACK DURING MODEL TRAINING. IT ALLOWS YOU TO VISUALIZE TRAINING METRICS LIKE LOSS, ACCURACY"
      ],
      "metadata": {
        "id": "MHpv4G0Vhvu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n"
      ],
      "metadata": {
        "id": "kWvGXFpqhzPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8-WHAT IS THE PURPOSE OF TENSORFLOW PLAYGROUND?**"
      ],
      "metadata": {
        "id": "2pMbuLkc3FhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER 8 -\n",
        "TENSORFLOW PLAYGROUND IS AN INTERACTIVE, BROWSER-BASED TOOL THAT HELPS USERS UNDERSTAND HOW NEURAL NETWORKS WORK. IT PROVIDES A VISUAL AND HANDS-ON WAY TO EXPERIMENT WITH VARIOUS MODEL CONFIGURATIONS."
      ],
      "metadata": {
        "id": "apwJQUI_h77Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9-WHAT IS NETRON, AND HOW IS IT USEFUL FOR DEEP LEARNING MODELS?**"
      ],
      "metadata": {
        "id": "Uo7wr6Gg3FeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER 9:\n",
        "NETRON IS A VIEWER FOR NEURAL NETWORK, DEEP LEARNING, AND MACHINE LEARNING MODELS. IT HELPS YOU VISUALIZE THE ARCHITECTURE OF MODELS SUCH AS TENSORFLOW, PYTORCH, KERAS, ONNX"
      ],
      "metadata": {
        "id": "TlbXwlSBiEPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10-WHAT IS THE DIFFERENCE BETWEEN TENSORFLOW AND PYTORCH?**"
      ],
      "metadata": {
        "id": "4JxW28nM3Fbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER 10:\n",
        "TENSORFLOW IS WIDELY USED FOR PRODUCTION AND LARGE-SCALE DEPLOYMENT, OFFERING ROBUST TOOLS AND SCALABILITY. PYTORCH, ON THE OTHER HAND, IS KNOWN FOR ITS DYNAMIC COMPUTATION GRAPH AND EASE OF EXPERIMENTATION, MAKING IT A FAVORITE IN THE RESEARCH COMMUNITY."
      ],
      "metadata": {
        "id": "lFYKaI_biISo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11-HOW DO YOU INSTALL PYTORCH?**"
      ],
      "metadata": {
        "id": "Q-01vHYm3FXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO INSTALL THE PYTORCH ( FOR GPU'S)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "N-Pd2MmJiV2p",
        "outputId": "ef7f4618-87b2-4590-f231-866dcf289a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.86)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW5WcXp-ihui",
        "outputId": "add05098-fb44-4a82-f262-7964ea0b944a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu118\n",
            "CUDA available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q12-WHAT IS THE BASIC STRUCTURE OF A PYTORCH NEURAL NETWORK?**"
      ],
      "metadata": {
        "id": "5UvXu0zd3FUH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER 12:\n",
        "A PYTORCH NEURAL NETWORK IS BUILT BY DEFINING A CLASS THAT INHERITS FROM NN.MODULE. LAYERS ARE DEFINED IN THE CONSTRUCTOR, AND THE FORWARD PASS IS WRITTEN IN THE FORWARD() METHOD."
      ],
      "metadata": {
        "id": "XmztpT2VkQt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13-WHAT IS THE SIGNIFICANCE OF TENSORS IN PYTORCH?**"
      ],
      "metadata": {
        "id": "SOx9DtJH3FRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER 13:\n",
        "TENSORS IN PYTORCH ARE MULTIDIMENSIONAL ARRAYS, SIMILAR TO NUMPY ARRAYS BUT WITH GPU ACCELERATION. THEY ARE THE FUNDAMENTAL BUILDING BLOCKS FOR STORING AND PROCESSING DATA IN DEEP LEARNING MODELS."
      ],
      "metadata": {
        "id": "WVCMAezukSxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q14-WHAT IS THE DIFFERENCE BETWEEN TORCH.TENSOR AND TORCH.CUDA.TENSOR IN PYTORCH?**"
      ],
      "metadata": {
        "id": "hF802-li3FPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER 14:\n",
        "TORCH.TENSOR REFERS TO TENSORS THAT RESIDE ON THE CPU, WHEREAS TORCH.CUDA.TENSOR REFERS TO TENSORS THAT ARE STORED AND PROCESSED ON THE GPU. GPU TENSORS ARE ESSENTIAL FOR FASTER TRAINING ON LARGE DATASETS."
      ],
      "metadata": {
        "id": "fzLXUNmzkUbQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15-WHAT IS THE PURPOSE OF THE TORCH.OPTIM MODULE IN PYTORCH?**"
      ],
      "metadata": {
        "id": "J7lQCNBm3FM7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER 15:\n",
        "THE TORCH.OPTIM MODULE PROVIDES VARIOUS OPTIMIZATION ALGORITHMS (E.G., SGD, ADAM) TO UPDATE MODEL WEIGHTS DURING TRAINING. IT PLAYS A CRUCIAL ROLE IN MINIMIZING LOSS AND IMPROVING MODEL PERFORMANCE."
      ],
      "metadata": {
        "id": "Sbn4A9fakWQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q16-WHAT ARE SOME COMMON ACTIVATION FUNCTIONS USED IN NEURAL NETWORKS?**"
      ],
      "metadata": {
        "id": "BxkjfYyD3FKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER 16:\n",
        "COMMON ACTIVATION FUNCTIONS INCLUDE RELU, SIGMOID, AND TANH. THESE FUNCTIONS INTRODUCE NON-LINEARITY INTO THE MODEL, ENABLING IT TO LEARN COMPLEX PATTERNS IN DATA."
      ],
      "metadata": {
        "id": "FsswRlQdkX8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q17- WHAT IS THE DIFFERENCE BETWEEN TORCH.NN.MODULE AND TORCH.NN.SEQUENTIAL IN PYTORCH?**"
      ],
      "metadata": {
        "id": "N3qQ_Rm93FHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER 17:\n",
        "TORCH.NN.MODULE IS USED FOR BUILDING FLEXIBLE, CUSTOM MODELS. TORCH.NN.SEQUENTIAL IS A SIMPLER ALTERNATIVE FOR MODELS WITH A LINEAR STACK OF LAYERS, WHERE LAYERS ARE ADDED IN ORDER."
      ],
      "metadata": {
        "id": "jWFXA2mAkZzQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q18- HOW CAN YOU MONITOR TRAINING PROGRESS IN TENSORFLOW 2.0?**"
      ],
      "metadata": {
        "id": "l3GH4siJ3E-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER 18:\n",
        "IN TENSORFLOW 2.0, TRAINING PROGRESS CAN BE MONITORED USING REAL-TIME CONSOLE OUTPUTS OR THROUGH TENSORBOARD, WHICH PROVIDES DETAILED VISUALIZATIONS OF TRAINING METRICS AND MODEL GRAPHS."
      ],
      "metadata": {
        "id": "vq5m1eZ_kbtR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q19-HOW DOES THE KERAS API FIT INTO TENSORFLOW 2.0?**"
      ],
      "metadata": {
        "id": "34EH2hVP3E0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER 19:\n",
        "THE KERAS API IS TIGHTLY INTEGRATED INTO TENSORFLOW 2.0. IT PROVIDES A CLEAN AND INTUITIVE INTERFACE FOR BUILDING, TRAINING, AND DEPLOYING DEEP LEARNING MODELS WITH MINIMAL CODE."
      ],
      "metadata": {
        "id": "Mu3fXwV5kdeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q20- WHAT IS AN EXAMPLE OF A DEEP LEARNING PROJECT THAT CAN BE IMPLEMENTED USING TENSORFLOW 2.0?**"
      ],
      "metadata": {
        "id": "DNvw7s9z3Ep6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER 20:\n",
        "AN EXAMPLE PROJECT USING TENSORFLOW 2.0 COULD BE A REAL-TIME IMAGE CLASSIFICATION SYSTEM (E.G., IDENTIFYING CATS VS. DOGS), TEXT SENTIMENT ANALYSIS, OR A HANDWRITTEN DIGIT RECOGNIZER USING THE MNIST DATASET."
      ],
      "metadata": {
        "id": "TLtz40qpkhHp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q21- WHAT IS THE MAIN ADVANTAGE OF USING PRE-TRAINED MODELS IN TENSORFLOW AND PYTORCH?**"
      ],
      "metadata": {
        "id": "xp9m7x1b3EcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER 21:\n",
        "PRE-TRAINED MODELS OFFER A HEAD START BY LEVERAGING KNOWLEDGE LEARNED FROM LARGE DATASETS. THEY SIGNIFICANTLY REDUCE TRAINING TIME AND OFTEN IMPROVE ACCURACY, ESPECIALLY WHEN FINE-TUNED FOR SPECIFIC TASKS."
      ],
      "metadata": {
        "id": "LnJIVyKndirL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRACTICAL QUESTIONS -"
      ],
      "metadata": {
        "id": "YGphdoG-ksOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1- HOW DO YOU INSTALL AND VERIFY THAT TENSORFLOW 2.0 WAS INSTALLED SUCCESSFULLY?"
      ],
      "metadata": {
        "id": "4C1YA1fqgbUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO INSTALL -\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEQN3Q0hhl91",
        "outputId": "f18e0d6a-6425-4b75-d9cd-c0c9c62ef336"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO CHECK IT IS INSTLAEED -\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OOr5CO_hs4f",
        "outputId": "14d42d72-ecf6-4e46-a657-a432d706ff31"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2- HOW CAN YOU DEFINE A SIMPLE FUNCTION IN TENSORFLOW 2.0 TO PERFORM ADDITION?"
      ],
      "metadata": {
        "id": "L_H_BHlQgaup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def add(a, b):\n",
        "    return a + b\n",
        "\n",
        "result = add(tf.constant(3), tf.constant(4))\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Zlx1nhKh4C6",
        "outputId": "266e3469-cb28-4fb2-f023-9410b4a384a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(7, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3- HOW CAN YOU CREATE A SIMPLE NEURAL NETWORK IN TENSORFLOW 2.0 WITH ONE HIDDEN LAYER?"
      ],
      "metadata": {
        "id": "3l8xZT8tgaV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(10,)),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "rUXZ3pWsh-_8",
        "outputId": "e7b6dd8c-8605-44b8-a195-fa1198b771e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m176\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m193\u001b[0m (772.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> (772.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m193\u001b[0m (772.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> (772.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4- HOW CAN YOU VISUALIZE THE TRAINING PROGRESS USING TENSORFLOW AND MATPLOTLIB?"
      ],
      "metadata": {
        "id": "b0nfOYbegZrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.random.rand(100, 10)\n",
        "y = np.random.rand(100, 1)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "history = model.fit(x, y, epochs=10, verbose=0)\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "gdXKEOj4iFAX",
        "outputId": "ef2dfb67-3da9-42cf-cbbd-9b0072056603"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5- HOW DO YOU INSTALL PYTORCH AND VERIFY THE PYTORCH INSTALLATION?"
      ],
      "metadata": {
        "id": "Tgz3wKpJgh3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtVAur4ZiIIh",
        "outputId": "1b6f8581-8555-48ef-ae70-9f80fc2656c8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6- HOW DO YOU CREATE A SIMPLE NEURAL NETWORK IN PYTORCH?"
      ],
      "metadata": {
        "id": "hNDA1YJBgjTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 8),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8, 1)\n",
        ")\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq3GcNYYiRVc",
        "outputId": "63971870-3326-478a-cdd3-f9dbd6032183"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7- HOW DO YOU DEFINE A LOSS FUNCTION AND OPTIMIZER IN PYTORCH?"
      ],
      "metadata": {
        "id": "PAOVq0XwgkrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n"
      ],
      "metadata": {
        "id": "wFeU7a3IimLh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8- HOW DO YOU IMPLEMENT A CUSTOM LOSS FUNCTION IN PYTORCH?"
      ],
      "metadata": {
        "id": "cYAlEqAvglyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss(pred, target):\n",
        "    return ((pred - target)**2).mean()\n",
        "\n",
        "x = torch.randn(5, 1)\n",
        "y = torch.randn(5, 1)\n",
        "print(custom_loss(x, y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptnRIWx-in2O",
        "outputId": "b267e0a5-19df-45e8-d7ff-07f1cdd2ebcb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.9659)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9- HOW DO YOU SAVE AND LOAD A TENSORFLOW MODEL?"
      ],
      "metadata": {
        "id": "ZtCGFSo1gnQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(8, activation='relu', input_shape=(4,)),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.save('model.h5')\n",
        "\n",
        "loaded_model = load_model('model.h5')\n",
        "loaded_model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "TwdB_Tj-isNU",
        "outputId": "249cb692-cfaf-4ffd-c520-41c85ee51590"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │              \u001b[38;5;34m40\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49\u001b[0m (196.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49</span> (196.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m49\u001b[0m (196.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49</span> (196.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}