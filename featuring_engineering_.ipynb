{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNR6ATt2T9Uev8v9axl6Whv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anuragsingh24082004/FUNCTIONS-PRACTICAL/blob/main/featuring_engineering_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "                          # Assignment"
      ],
      "metadata": {
        "id": "kkl9Tu4KETOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "link to open in collab - https://colab.research.google.com/drive/1GseOlMmgHzEjoazZCjJtxSV8ZIGor6di?usp=sharing"
      ],
      "metadata": {
        "id": "XHAkLDI2HJ6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.1-  What is a parameter ?"
      ],
      "metadata": {
        "id": "Eg2EaKzpEndm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer- Parameter is Internal variables learned from training data for example - coeffecient in linear regression"
      ],
      "metadata": {
        "id": "-v7S9w4UmADE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.2- What is correlation ? What does negative correlation mean ?"
      ],
      "metadata": {
        "id": "hrEydPKiE8TH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - The value of correlation ranges between -1 and 1 . Correlation is a statistical measure that describes the extentto which two variables are related to each other. It quantifies the degree to which changes in one variable predict changes in another."
      ],
      "metadata": {
        "id": "Mu51cmZUmbTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.3- Define Machine Learning . What are the main components in Machine Learning?"
      ],
      "metadata": {
        "id": "-QesKL9NFKqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - Machine Learning (ML) refers to the technology and algorithms that enable computers to learn from and make decisions based on data. It is a subset of artificial intelligence where systems improve their performance on specific tasks through experience. By using statistical techniques, ML models identify patterns and make predictions without explicit programming for each task. Over time, as more data is introduced, the models enhance their accuracy and efficiency.\n",
        "\n",
        "The main components of in Machine Learning are as follows-\n",
        "* Data: The foundation of ML, involving collecting and preparing datasets for training and evaluation.\n",
        "* Training: The process of feeding data to the model to learn patterns and adjust parameters.\n",
        "* Model: The mathematical representation or algorithm that learns from data to make predictions or decisions.\n",
        "* Evaluation: Assessing the model's performance using a separate dataset to ensure it generalizes well.\n",
        "* Hyperparameters: Configurable settings that influence the learning process, like learning rate and number of layers."
      ],
      "metadata": {
        "id": "lnxsYv_Aqw3-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.4- How does loss value help in determining whether the model is good or not ?"
      ],
      "metadata": {
        "id": "BAprJ8nnFW-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - The loss value quantifies how well or poorly a model's predictions match the actual outcomes. It is a critical metric used during the training of a model to guide the optimization process. \\\n",
        "\n",
        "it helps determining the model quality by -\n",
        "* Measuring The the accuracy\n",
        "* BY Traning Guidance - The optimization algorithm adjusts the model's parameters to minimize the loss value, improving the model's performance.\n",
        "* Early Stopping: By monitoring the loss, one can decide when to stop training to prevent overfitting, ensuring the model generalizes well to new data.\n",
        "* Comparison Metric: Loss value allows comparison between different models or algorithms to choose the best-performing one."
      ],
      "metadata": {
        "id": "YyHh00BWvj7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.5- What are continuous and categorical variables?"
      ],
      "metadata": {
        "id": "n9XV_LKVFnuA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer -\n",
        "* Continuous Variables -\n",
        "\n",
        "Definition: Continuous variables can take on any value within a range. They are often measured on a scale or continuum and can be infinitely divided into finer values.\n",
        "\n",
        "* Categorical Variables -\n",
        "\n",
        "Definition: Categorical variables, also known as discrete or qualitative variables, represent categories or groups. These variables take on a limited number of distinct values."
      ],
      "metadata": {
        "id": "S9tXX-hfzIsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.6- How do we handle categorical variables in Machine Learning ? What are the common techniques?"
      ],
      "metadata": {
        "id": "Fa7Zl_LPFyL1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer -\n",
        "* We handle categorical variables in Machine Learning by these common techniques -\n",
        "\n",
        "Ordinal Encoding: Used for ordinal data where the categories have a natural order. For example, Low=1, Medium=2, High=3.\n",
        "\n",
        "Target Encoding: Replaces each category with the mean of the target variable for that category. This can introduce information about the target variable but also risks overfitting.\n",
        "\n",
        "Frequency Encoding: Replaces categories with their frequency count or proportion in the dataset."
      ],
      "metadata": {
        "id": "pJko7Pojzpw2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.7- What do you mean by training and testing a dataset ?"
      ],
      "metadata": {
        "id": "VeNMhDy4GGKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer -\n",
        "\n",
        "* Training: Teaching the model using part of the data to learn patterns and adjust parameters for accurate predictions.\n",
        "\n",
        "* Testing: Evaluating the trained model's performance on unseen data to ensure it generalizes well, using metrics like accuracy and precision."
      ],
      "metadata": {
        "id": "zp2dS0tl0nlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.8- What is sklearn.preprocessing ?"
      ],
      "metadata": {
        "id": "wm6hwWUvGWdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - sklearn.preprocessing is a module in the scikit-learn library used for data preprocessing and feature scaling. It includes functions and classes to transform raw data into a suitable format for machine learning algorithms."
      ],
      "metadata": {
        "id": "W1qUTf5q1SNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.9- What is a Test set ?"
      ],
      "metadata": {
        "id": "Bzg0Q0x8GijX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - A Test set is a subset of your dataset used to evaluate the performance of a trained machine learning model. Unlike the training set, the test set contains data that the model has not seen during training. This ensures that the model’s performance metrics reflect its ability to generalize to new, unseen data, thereby assessing its real-world effectiveness"
      ],
      "metadata": {
        "id": "9viHHAAi1bot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.10- How do we split data for model fitting(training and testing) in Python ? How do you approach a Machine Learning Problem ?"
      ],
      "metadata": {
        "id": "eQmq5RIxGnW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer -"
      ],
      "metadata": {
        "id": "nGLpW5z32fE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# to Load the dataset\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target)\n",
        "\n",
        "# to Perform train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# for Model selection and training\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# for Model evaluation\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3ll9zvN7FZYc",
        "outputId": "1447b55e-37e5-428d-b617-d7626ad0893c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approaching a Machine Learning Problem\n",
        "Define the Problem: Understand the objective and success criteria.\n",
        "\n",
        "Gather Data: Collect and clean the data.\n",
        "\n",
        "EDA: Perform Exploratory Data Analysis to understand data.\n",
        "\n",
        "Feature Engineering: Create and select relevant features.\n",
        "\n",
        "Split Data: Use train_test_split for training and testing sets.\n",
        "\n",
        "Model Selection: Choose appropriate algorithms.\n",
        "\n",
        "Model Training: Train the model with training data.\n",
        "\n",
        "Evaluation: Evaluate using testing data and metrics.\n",
        "\n",
        "Tuning: Optimize model parameters.\n",
        "\n",
        "Deployment: Deploy the model for use.\n",
        "\n",
        "Monitoring: Continuously monitor and update the model."
      ],
      "metadata": {
        "id": "nn1bTIoTGwiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.11- Why do we have to perform EDA before fitting a model to the data ?"
      ],
      "metadata": {
        "id": "tJNp94-9G7Fa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - We Perform EDA to ensure that the data is clean , relevant, and well-understood, which lays a solid foundation for building accurate and robust machine learning models."
      ],
      "metadata": {
        "id": "WJThw9zx25A4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.12- What is correlation ?"
      ],
      "metadata": {
        "id": "SBt94b6hHFFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - Correlation Vlues Ranges From -1 to +1 .Correlation is a statistical measure that describes the extent to which two variables are related to each other. It quantifies the degree to which changes in one variable predict changes in another."
      ],
      "metadata": {
        "id": "gLeoUiMS3XnM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.13- What does negative correlation mean ?"
      ],
      "metadata": {
        "id": "Vc7gQFd4HKOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - Negative correlation means that as one variable increases, the other variable tends to decrease. In other words, they move in opposite directions."
      ],
      "metadata": {
        "id": "4EMUILmJ3xhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.14- How can you find correlation between variables in Python ?"
      ],
      "metadata": {
        "id": "HrBRhk5xHSg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - To find correlation between variables in Python, we can use the pandas library. After Loading our dataset into a DataFrame, then use the corr() method to calculate the correlation matrix. This matrix shows the correlation coefficients between all pairs of variables, indicating their relationships. It's a straightforward way to assess dependencies in your data."
      ],
      "metadata": {
        "id": "mmFzH9j43-EP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.15- What is causation ? Explain difference between correlation and causation with an example ?"
      ],
      "metadata": {
        "id": "mTo9oRwLHgeM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - Causation indicates a cause-and-effect relationship between two variables, where one variable directly affects the other. In other words, changes in one variable cause changes in the other.\n",
        "\n",
        "* Difference between Correlation and Causation -\n",
        "\n",
        "Correlation: Measures the relationship or association between two variables, indicating how they move together. However, it does not imply that one variable causes the other to change.\n",
        "\n",
        "Causation: Indicates that one variable directly influences or causes a change in another variable."
      ],
      "metadata": {
        "id": "eEUHJLqf4kM0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.16- What is an optimizer ? What are the different types of optimizers ? Explain each with an example ."
      ],
      "metadata": {
        "id": "ms-dpds4H1ma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - An optimizer in machine learning is an algorithm or method used to adjust the parameters of a model to minimize the loss function during training. Optimizers play a crucial role in improving the model’s accuracy and efficiency.\n",
        "\n",
        "Types of Optimizers -\n",
        "\n",
        "* Gradient Descent (GD)\n",
        "\n",
        "Example: Standard Gradient Descent updates parameters using the entire dataset for each iteration\n",
        "\n",
        "* Stochastic Gradient Descent (SGD)\n",
        "\n",
        "Example: Updates parameters using a single data point for each iteration.\n",
        "\n",
        "* Mini-Batch Gradient Descent\n",
        "\n",
        "Example: Updates parameters using a small batch of data points for each iteration.\n",
        "\n",
        "* Adam (Adaptive Moment Estimation)\n",
        "\n",
        "Example: Combines the advantages of two other extensions of SGD, namely Adagrad and RMSprop.\n",
        "\n",
        "* RMSprop (Root Mean Square Propagation)\n",
        "\n",
        "Example: Adapts the learning rate based on the average of recent magnitudes of the gradients for each parameter.\n",
        "\n",
        "* Adagrad (Adaptive Gradient Algorithm)\n",
        "\n",
        "Example: Adapts the learning rate for each parameter, performing well on sparse data."
      ],
      "metadata": {
        "id": "gSFWsiNx7nbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.17- What is sklearn.linear_model ?"
      ],
      "metadata": {
        "id": "-bxfQ-UwIRsQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - sklearn.linear_model is a module in the scikit-learn library that provides various linear models for regression and classification tasks. It includes algorithms that fit linear relationships between inputs and outputs"
      ],
      "metadata": {
        "id": "Q6IdezDb887t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.18- What does model.fit() do ? What arguments must be given ?"
      ],
      "metadata": {
        "id": "BFh1i8BLIYb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - model.fit() trains the model , adjust the parameters and learns the patterns from the input and understand the relationship between input features and target variables .\n",
        "\n",
        "Arguments that must be given -\n",
        "\n",
        "* X (Features): The input data (features) used to train the model. This is typically a 2D array or DataFrame where each row represents a data point and each column represents a feature.\n",
        "\n",
        "* y (Target Variable): The output data (target variable) that the model aims to predict. This is typically a 1D array or Series where each element corresponds to the target value for a data point in X."
      ],
      "metadata": {
        "id": "YDCILR5WAflO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.19- What does model.predict() do ? What arguments must be given ?"
      ],
      "metadata": {
        "id": "PwU2kMxyIkHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - model.predict() is a method used to make predictions using a trained machine learning model. It takes new input data and generates corresponding output predictions based on what the model has learned during training .\n",
        "\n",
        "Must Given Arguments -\n",
        "\n",
        "* X (Features): The input data (features) for which you want to make predictions. This is typically a 2D array or DataFrame where each row represents a data point and each column represents a feature."
      ],
      "metadata": {
        "id": "4S78TSaDBu9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.20- What are continuous and categorical variables?"
      ],
      "metadata": {
        "id": "0kFXupNZIvV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer -\n",
        "* Continuous Variables -\n",
        "\n",
        "Definition: Continuous variables can take on any value within a range. They are often measured on a scale or continuum and can be infinitely divided into finer values.\n",
        "\n",
        "* Categorical Variables -\n",
        "\n",
        "Definition: Categorical variables, also known as discrete or qualitative variables, represent categories or groups. These variables take on a limited number of distinct values."
      ],
      "metadata": {
        "id": "MsqqQaWdCJlU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q21- What is feature scaling ? How does it help in Machine Learning ?"
      ],
      "metadata": {
        "id": "nPl6n7WhI3fX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - Feature scaling is a technique used to normalize or standardize the range of independent variables (features) in a dataset. It ensures that all features contribute equally to the model, improving its performance and accuracy.\n",
        "\n",
        "* It helps in Machine Learning (ML) To improve Converg;ence , in enhancing model performance , it reduces sensitivity to feature magnitudes and to faciliate comparisons ."
      ],
      "metadata": {
        "id": "X75FVC5RCZ7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.22- How do we perform scaling in Python ?"
      ],
      "metadata": {
        "id": "v2BIyInOJDE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - To perform scaling in Python, you can use the sklearn.preprocessing module from the scikit-learn library . to  perform the scaling in python we use two types of technniques\n",
        "the first one is Z-Score normalization and secoond one is Min-Max Scaling."
      ],
      "metadata": {
        "id": "TRf6cF9EDV4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.23- What is sklearn.preprocessing?"
      ],
      "metadata": {
        "id": "YhPTc3tWJKlq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - sklearn.preprocessing is a module in the scikit-learn library used for data preprocessing and feature scaling. It includes functions and classes to transform raw data into a suitable format for machine learning algorithms."
      ],
      "metadata": {
        "id": "R1Job6WgEKdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.24- How do we split data for model fitting ( traing and testing) in Python ?"
      ],
      "metadata": {
        "id": "MyzuEEGtJTvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - To split data for model fitting in Python, we can use the train_test_split function from the sklearn.model_selection module. This function allows us to split your dataset into training and testing sets efficiently."
      ],
      "metadata": {
        "id": "k5Y8-q5REUo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for example -\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming X is your feature set and y is your target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# X_train and y_train are used for training the model\n",
        "# X_test and y_test are used for testing the model\n"
      ],
      "metadata": {
        "id": "d88-c-H7EpjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.25- Explain data encoding ?"
      ],
      "metadata": {
        "id": "dipBLnB-Jr3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - Data encoding is a crucial preprocessing step that transforms categorical data into a format suitable for machine learning algorithms, ensuring accurate and efficient model performance."
      ],
      "metadata": {
        "id": "Imi9RY5qE1FL"
      }
    }
  ]
}